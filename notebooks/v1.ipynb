{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35472663-a1e6-4228-a178-5006b2effe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43896a6-ec52-44e5-a44e-cd7fabd18f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RAW_PATH = \"../data/RAW/RT-BENE.zip\" \n",
    "DATA_INTER_PATH = \"../data/intermediate/\"\n",
    "DATA_PATH = f\"{DATA_INTER_PATH}/RT-BENE\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    !unzip -q $DATA_RAW_PATH $DATA_INTER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da68634c-20ed-4ada-967b-a10f34029522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb3c96d-687c-483c-a0d3-1144962d32b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blink_id</th>\n",
       "      <th>left_eye</th>\n",
       "      <th>right_eye</th>\n",
       "      <th>video</th>\n",
       "      <th>blink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_left_000001_rgb.png</td>\n",
       "      <td>0_right_000001_rgb.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0_left_000002_rgb.png</td>\n",
       "      <td>0_right_000002_rgb.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0_left_000003_rgb.png</td>\n",
       "      <td>0_right_000003_rgb.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0_left_000004_rgb.png</td>\n",
       "      <td>0_right_000004_rgb.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0_left_000005_rgb.png</td>\n",
       "      <td>0_right_000005_rgb.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107345</th>\n",
       "      <td>107345</td>\n",
       "      <td>16_left_009059_rgb.png</td>\n",
       "      <td>16_right_009059_rgb.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107346</th>\n",
       "      <td>107346</td>\n",
       "      <td>16_left_009060_rgb.png</td>\n",
       "      <td>16_right_009060_rgb.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107347</th>\n",
       "      <td>107347</td>\n",
       "      <td>16_left_009061_rgb.png</td>\n",
       "      <td>16_right_009061_rgb.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107348</th>\n",
       "      <td>107348</td>\n",
       "      <td>16_left_009062_rgb.png</td>\n",
       "      <td>16_right_009062_rgb.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107349</th>\n",
       "      <td>107349</td>\n",
       "      <td>16_left_009063_rgb.png</td>\n",
       "      <td>16_right_009063_rgb.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107350 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        blink_id                left_eye                right_eye  video  \\\n",
       "0              0   0_left_000001_rgb.png   0_right_000001_rgb.png      0   \n",
       "1              1   0_left_000002_rgb.png   0_right_000002_rgb.png      0   \n",
       "2              2   0_left_000003_rgb.png   0_right_000003_rgb.png      0   \n",
       "3              3   0_left_000004_rgb.png   0_right_000004_rgb.png      0   \n",
       "4              4   0_left_000005_rgb.png   0_right_000005_rgb.png      0   \n",
       "...          ...                     ...                      ...    ...   \n",
       "107345    107345  16_left_009059_rgb.png  16_right_009059_rgb.png     16   \n",
       "107346    107346  16_left_009060_rgb.png  16_right_009060_rgb.png     16   \n",
       "107347    107347  16_left_009061_rgb.png  16_right_009061_rgb.png     16   \n",
       "107348    107348  16_left_009062_rgb.png  16_right_009062_rgb.png     16   \n",
       "107349    107349  16_left_009063_rgb.png  16_right_009063_rgb.png     16   \n",
       "\n",
       "        blink  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "107345      0  \n",
       "107346      0  \n",
       "107347      0  \n",
       "107348      0  \n",
       "107349      0  \n",
       "\n",
       "[107350 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"{DATA_PATH}/blinks.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358eef2-c764-4557-86b2-104413d7c6ff",
   "metadata": {},
   "source": [
    "### How many videos do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df339bd-3747-4f21-b2a2-3821ff303e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids = np.unique(data[\"video\"])\n",
    "video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f2a1e-1858-4671-a36e-8895f9c4008c",
   "metadata": {},
   "source": [
    "### Total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc1945a-e8b2-49d4-81fe-06c44aa8364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107350"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"blink_id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8248cca0-6ca5-4e58-97c0-5c80fab138ba",
   "metadata": {},
   "source": [
    "### How many images per video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86a9305-0d25-4830-8dee-50d87b091bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images in video</th>\n",
       "      <th>% blink frames</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12865</td>\n",
       "      <td>7.236689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8671</td>\n",
       "      <td>1.476185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8702</td>\n",
       "      <td>9.066881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3205</td>\n",
       "      <td>5.210608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4750</td>\n",
       "      <td>2.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5355</td>\n",
       "      <td>2.054155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1857</td>\n",
       "      <td>8.023694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6108</td>\n",
       "      <td>7.514735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4210</td>\n",
       "      <td>1.068884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16559</td>\n",
       "      <td>2.131771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12817</td>\n",
       "      <td>5.399079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>935</td>\n",
       "      <td>2.459893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9586</td>\n",
       "      <td>3.077405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5371</td>\n",
       "      <td>4.002979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1810</td>\n",
       "      <td>1.602210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4549</td>\n",
       "      <td>0.923280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Images in video  % blink frames\n",
       "video                                 \n",
       "0                12865        7.236689\n",
       "1                 8671        1.476185\n",
       "2                 8702        9.066881\n",
       "3                 3205        5.210608\n",
       "4                 4750        2.736842\n",
       "5                 5355        2.054155\n",
       "7                 1857        8.023694\n",
       "8                 6108        7.514735\n",
       "9                 4210        1.068884\n",
       "10               16559        2.131771\n",
       "11               12817        5.399079\n",
       "12                 935        2.459893\n",
       "13                9586        3.077405\n",
       "14                5371        4.002979\n",
       "15                1810        1.602210\n",
       "16                4549        0.923280"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_per_video = data.groupby(by=[\"video\"]).count()\n",
    "blinks_per_video = data.loc[data[\"blink\"] == 1].groupby(by=\"video\").count()\n",
    "blinks_per_video = blinks_per_video.div(data_per_video, level=\"video\") * 100\n",
    "data_per_video = pd.concat([data_per_video[\"blink_id\"], blinks_per_video[\"blink\"]], axis=1, keys=[\"Images in video\",\"% blink frames\"])\n",
    "data_per_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f11ec-797e-43d1-bd26-187feb077b43",
   "metadata": {},
   "source": [
    "Previous data shows that a rebalancing method will have to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26326774-e988-4981-9b8b-78a5c887dcb1",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "To have a proper test partition we are going to separate the dataset in two sets of videos. One will be used for training and the other one for testing.\n",
    "We will select the videos ids 13, 14, 16 as the testing videos because it's images represent around 20% of the total dataset and the percentage of blinks is similar to the rest of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e0771-9a36-4378-8798-f79866c728de",
   "metadata": {},
   "source": [
    "#### Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252c72ab-cba5-44d7-bb01-2a59eca9e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 15]\n",
      "validation: [8]\n",
      "testing: [13, 14, 16]\n"
     ]
    }
   ],
   "source": [
    "testing_ids = [13,14,16]\n",
    "validation_ids = [8]\n",
    "training_ids = np.delete(video_ids, np.array(testing_ids)-1)\n",
    "training_ids = np.delete(training_ids, np.array(validation_ids)-1)\n",
    "training_ids = training_ids.tolist()\n",
    "print(f\"train: {training_ids}\\nvalidation: {validation_ids}\\ntesting: {testing_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8601f926-4522-4fe3-bb07-d2819cfebf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 81736\n",
      "val_data: 6108\n",
      "test_data: 19506\n"
     ]
    }
   ],
   "source": [
    "train_data = data.loc[data[\"video\"].isin(training_ids)]\n",
    "print(f\"train_data: {train_data.shape[0]}\")\n",
    "val_data = data.loc[data[\"video\"].isin(validation_ids)]\n",
    "print(f\"val_data: {val_data.shape[0]}\")\n",
    "test_data = data.loc[data[\"video\"].isin(testing_ids)]\n",
    "print(f\"test_data: {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bc867-e450-423b-a8fe-56df94d8aec8",
   "metadata": {},
   "source": [
    "#### Generic generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc1e6cf-52fc-4abb-90e1-acfbfcf52836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "class RTBeneDataset:\n",
    "    def __init__(self, phase: str, data: pd.DataFrame, mean: float, std: float, transforms = None):\n",
    "        self.phase = phase\n",
    "        self.data = data\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        if self.phase == \"train\":\n",
    "            #Shuffle the data\n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "        else:\n",
    "            self.data = self.data.reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "    def __getitem(self, idx):\n",
    "        row = self.data.loc[idx,[\"left_eye\", \"right_eye\"]].to_list(), self.data.loc[idx,[\"blink\"]].to_list()[0]\n",
    "        return row\n",
    "        #return RTBeneDataset.load_row(DATA_PATH, row)\n",
    "    \n",
    "    def __call__(self):\n",
    "        for i in range(self.data.shape[0]):\n",
    "            yield self.__getitem(i)\n",
    "            \n",
    "            if i == (self.data.shape[0] -1):\n",
    "                # When all the dataset is readed, reshuffle again\n",
    "                self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "       \n",
    "    @staticmethod\n",
    "    def load_row(x, y):\n",
    "        print(x)\n",
    "        left_image = cv2.imread(f\"{DATA_PATH}/images/{x[0]}\")\n",
    "        right_image = cv2.imread(f\"{DATA_PATH}/images/{x[1]}\")\n",
    "        return (left_image/255, right_image/255), y\n",
    "    \n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def tf_load_row(x, y):\n",
    "        image_l = tf.io.read_file(tf.strings.join([f\"{DATA_PATH}/images/\", x[0]]))\n",
    "        image_r = tf.io.read_file(tf.strings.join([f\"{DATA_PATH}/images/\", x[1]]))\n",
    "        image_l = tf.image.decode_png(image_l, channels=3)\n",
    "        image_r = tf.image.decode_png(image_r, channels=3)\n",
    "        return (image_l/255, image_r/255), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ecc920-9f14-4400-8484-480a0e9065c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_RTB = RTBeneDataset(\"train\", train_data, 127.5, 1)\n",
    "val_RTB = RTBeneDataset(\"val\", val_data, 127.5, 1)\n",
    "test_RTB = RTBeneDataset(\"val\", test_data, 127.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd8d481-5151-4a09-bb21-e3ece76b6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 12:54:11.354113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.385436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.385780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.386932: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-05 12:54:11.387544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.388152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.388742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.745599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.745937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.746228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-05 12:54:11.746503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9627 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(train_RTB, \n",
    "                                               output_types=(tf.string, tf.int32), \n",
    "                                               output_shapes=((2),())).map(RTBeneDataset.tf_load_row, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE).batch(batch_size).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(val_RTB, \n",
    "                                               output_types=(tf.string, tf.int32), \n",
    "                                               output_shapes=((2),())).map(RTBeneDataset.tf_load_row, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_RTB, \n",
    "                                               output_types=(tf.string, tf.int32), \n",
    "                                               output_shapes=((2),())).map(RTBeneDataset.tf_load_row, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94104655-132f-4517-b98e-5c36107623c9",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ccc5e52-356e-41cc-9434-448d84f4189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7dd581f-c27d-4bc3-9084-d45cc726e623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 36, 60, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 36, 60, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " vgg_left (Functional)          (None, 1, 1, 512)    14714688    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " vgg_right (Functional)         (None, 1, 1, 512)    14714688    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 1, 1024)   0           ['vgg_left[0][0]',               \n",
      "                                                                  'vgg_right[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          131200      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,560,705\n",
      "Trainable params: 29,560,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_eye = keras.Input(shape=(36, 60, 3))\n",
    "right_eye = keras.Input(shape=(36, 60, 3))\n",
    "vgg_left = VGG16(weights=\"imagenet\", include_top=False, input_shape=(36, 60, 3))\n",
    "vgg_left._name = \"vgg_left\"\n",
    "vgg_right = VGG16(weights=\"imagenet\", include_top=False, input_shape=(36, 60, 3))\n",
    "vgg_right._name = \"vgg_right\"\n",
    "left_feat_extractor = vgg_left(left_eye)\n",
    "right_feat_extractor = vgg_right(right_eye)\n",
    "concat = keras.layers.Concatenate()([left_feat_extractor, right_feat_extractor])\n",
    "flat = keras.layers.Flatten()(concat)\n",
    "dense_1 = keras.layers.Dense(128, activation=\"relu\")(flat)\n",
    "out = keras.layers.Dense(1, activation=\"sigmoid\")(dense_1)\n",
    "\n",
    "model = keras.Model(inputs=([left_eye, right_eye]), outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5246c770-00a1-45de-a158-e019f4743882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def F1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "model.compile(optimizer=keras.optimizers.Adam(), \n",
    "              loss=keras.losses.BinaryCrossentropy(), \n",
    "              metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall(), F1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ccf3233-fa62-48fe-b367-6135623d9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 12:54:20.313724: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n",
      "2022-02-05 12:54:21.090801: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-02-05 12:54:22.706547: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 90s 134ms/step - loss: 0.0979 - binary_accuracy: 0.9712 - precision: 0.7782 - recall: 0.4685 - F1_score: 0.4610 - val_loss: 0.2977 - val_binary_accuracy: 0.9302 - val_precision: 0.9756 - val_recall: 0.0871 - val_F1_score: 0.0745\n",
      "Epoch 2/10\n",
      "638/638 [==============================] - 85s 131ms/step - loss: 0.0312 - binary_accuracy: 0.9897 - precision: 0.9009 - recall: 0.8573 - F1_score: 0.8632 - val_loss: 0.3979 - val_binary_accuracy: 0.9274 - val_precision: 1.0000 - val_recall: 0.0224 - val_F1_score: 0.0406\n",
      "Epoch 3/10\n",
      "638/638 [==============================] - 83s 131ms/step - loss: 0.0267 - binary_accuracy: 0.9912 - precision: 0.9144 - recall: 0.8785 - F1_score: 0.8737 - val_loss: 0.1268 - val_binary_accuracy: 0.9526 - val_precision: 1.0000 - val_recall: 0.3624 - val_F1_score: 0.5057\n",
      "Epoch 4/10\n",
      "638/638 [==============================] - 82s 129ms/step - loss: 0.0199 - binary_accuracy: 0.9933 - precision: 0.9320 - recall: 0.9133 - F1_score: 0.9098 - val_loss: 0.2725 - val_binary_accuracy: 0.9310 - val_precision: 1.0000 - val_recall: 0.0859 - val_F1_score: 0.1480\n",
      "Epoch 5/10\n",
      "638/638 [==============================] - 82s 129ms/step - loss: 0.0236 - binary_accuracy: 0.9918 - precision: 0.9154 - recall: 0.8935 - F1_score: 0.8922 - val_loss: 0.3469 - val_binary_accuracy: 0.9240 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_F1_score: 0.0000e+00\n",
      "Epoch 6/10\n",
      "638/638 [==============================] - 82s 129ms/step - loss: 0.0219 - binary_accuracy: 0.9923 - precision: 0.9218 - recall: 0.8981 - F1_score: 0.8955 - val_loss: 0.1554 - val_binary_accuracy: 0.9402 - val_precision: 0.9709 - val_recall: 0.2188 - val_F1_score: 0.3433\n",
      "Epoch 7/10\n",
      "638/638 [==============================] - 83s 131ms/step - loss: 0.0176 - binary_accuracy: 0.9941 - precision: 0.9440 - recall: 0.9194 - F1_score: 0.9248 - val_loss: 0.2260 - val_binary_accuracy: 0.9603 - val_precision: 0.9739 - val_recall: 0.4902 - val_F1_score: 0.6258\n",
      "Epoch 8/10\n",
      "638/638 [==============================] - 83s 129ms/step - loss: 0.0131 - binary_accuracy: 0.9956 - precision: 0.9552 - recall: 0.9431 - F1_score: 0.9383 - val_loss: 0.2670 - val_binary_accuracy: 0.9284 - val_precision: 0.9231 - val_recall: 0.0530 - val_F1_score: 0.0899\n",
      "Epoch 9/10\n",
      "638/638 [==============================] - 83s 130ms/step - loss: 0.0138 - binary_accuracy: 0.9953 - precision: 0.9552 - recall: 0.9360 - F1_score: 0.9357 - val_loss: 0.1153 - val_binary_accuracy: 0.9608 - val_precision: 0.9738 - val_recall: 0.4923 - val_F1_score: 0.6371\n",
      "Epoch 10/10\n",
      "638/638 [==============================] - 82s 128ms/step - loss: 0.0156 - binary_accuracy: 0.9951 - precision: 0.9531 - recall: 0.9333 - F1_score: 0.9325 - val_loss: 0.1550 - val_binary_accuracy: 0.9333 - val_precision: 0.9825 - val_recall: 0.1228 - val_F1_score: 0.2012\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "run_id = f'{model.name}-{datetime.now().strftime(\"%m-%H%M%S\")}'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f\"models/{run_id}/\" + \"{epoch:02d}-{val_F1_score:.2f}\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_F1_score',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{run_id}\", update_freq=100,)\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "          validation_data=val_dataset, \n",
    "          epochs=10, \n",
    "          steps_per_epoch=int(train_data.shape[0]/batch_size), \n",
    "          validation_steps=int(val_data.shape[0]/batch_size),\n",
    "          callbacks=[model_checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a994f3-5e62-49fe-b010-cd942a7bbaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 16s 101ms/step - loss: 0.0708 - binary_accuracy: 0.9801 - precision: 0.6127 - recall: 0.8025 - F1_score: 0.6522\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"models/model-02-125418/09-0.64\")\n",
    "results = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0a960-fdd7-459c-84cd-d6165ad917e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
